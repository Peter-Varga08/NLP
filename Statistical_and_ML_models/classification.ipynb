{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8274e4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, list_metrics, load_metric\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d6cce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = load_dataset(\"GroNLP/ik-nlp-22_pestyle\", \"full\", data_dir=\"../IK_NLP_22_PESTYLE\")['train'].to_pandas()\n",
    "df_train = df_train[df_train.modality != 'ht']\n",
    "df_test = load_dataset(\"GroNLP/ik-nlp-22_pestyle\", \"mask_subject\", data_dir=\"../IK_NLP_22_PESTYLE\")['test'].to_pandas()\n",
    "df_test = df_test[df_test.modality != 'ht']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7af806cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>modality</th>\n",
       "      <th>src_text</th>\n",
       "      <th>mt_text</th>\n",
       "      <th>tgt_text</th>\n",
       "      <th>edit_time</th>\n",
       "      <th>k_total</th>\n",
       "      <th>k_letter</th>\n",
       "      <th>k_digit</th>\n",
       "      <th>...</th>\n",
       "      <th>len_pause_geq_1000</th>\n",
       "      <th>num_annotations</th>\n",
       "      <th>n_insert</th>\n",
       "      <th>n_delete</th>\n",
       "      <th>n_substitute</th>\n",
       "      <th>n_shift</th>\n",
       "      <th>bleu</th>\n",
       "      <th>chrf</th>\n",
       "      <th>ter</th>\n",
       "      <th>aligned_edit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>t2</td>\n",
       "      <td>pe2</td>\n",
       "      <td>UN peacekeepers, whom arrived in Haiti after t...</td>\n",
       "      <td>I soldati della pace dell'ONU, che sono arriva...</td>\n",
       "      <td>Le forze di pace delle Nazioni Unite, arrivate...</td>\n",
       "      <td>128.078995</td>\n",
       "      <td>179</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>87014</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.290001</td>\n",
       "      <td>56.939999</td>\n",
       "      <td>58.064999</td>\n",
       "      <td>REF:  i  soldati della pace dell'onu, che     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>t3</td>\n",
       "      <td>pe1</td>\n",
       "      <td>UN peacekeepers, whom arrived in Haiti after t...</td>\n",
       "      <td>Le forze di pace delle Nazioni Unite, arrivate...</td>\n",
       "      <td>Le forze di pace dell'ONU, arrivate ad Haiti d...</td>\n",
       "      <td>141.500000</td>\n",
       "      <td>57</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>98938</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.660004</td>\n",
       "      <td>84.959999</td>\n",
       "      <td>18.518999</td>\n",
       "      <td>REF:  le forze di pace delle nazioni unite,   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>t2</td>\n",
       "      <td>pe2</td>\n",
       "      <td>According to the lawsuit, waste from the UN ca...</td>\n",
       "      <td>Secondo la causa, i rifiuti del campo delle Na...</td>\n",
       "      <td>Secondo l'accusa, i rifiuti del campo delle Na...</td>\n",
       "      <td>66.817001</td>\n",
       "      <td>67</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>45450</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.480003</td>\n",
       "      <td>83.419998</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>REF:  secondo la causa,    i rifiuti del campo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id subject_id modality  \\\n",
       "1       11         t2      pe2   \n",
       "2       11         t3      pe1   \n",
       "4       12         t2      pe2   \n",
       "\n",
       "                                            src_text  \\\n",
       "1  UN peacekeepers, whom arrived in Haiti after t...   \n",
       "2  UN peacekeepers, whom arrived in Haiti after t...   \n",
       "4  According to the lawsuit, waste from the UN ca...   \n",
       "\n",
       "                                             mt_text  \\\n",
       "1  I soldati della pace dell'ONU, che sono arriva...   \n",
       "2  Le forze di pace delle Nazioni Unite, arrivate...   \n",
       "4  Secondo la causa, i rifiuti del campo delle Na...   \n",
       "\n",
       "                                            tgt_text   edit_time  k_total  \\\n",
       "1  Le forze di pace delle Nazioni Unite, arrivate...  128.078995      179   \n",
       "2  Le forze di pace dell'ONU, arrivate ad Haiti d...  141.500000       57   \n",
       "4  Secondo l'accusa, i rifiuti del campo delle Na...   66.817001       67   \n",
       "\n",
       "   k_letter  k_digit  ...  len_pause_geq_1000  num_annotations  n_insert  \\\n",
       "1       102        0  ...               87014                2       0.0   \n",
       "2        27        0  ...               98938                1       1.0   \n",
       "4        52        0  ...               45450                2       2.0   \n",
       "\n",
       "   n_delete  n_substitute  n_shift       bleu       chrf        ter  \\\n",
       "1       2.0          15.0      1.0  29.290001  56.939999  58.064999   \n",
       "2       2.0           2.0      0.0  74.660004  84.959999  18.518999   \n",
       "4       1.0           4.0      0.0  65.480003  83.419998  25.000000   \n",
       "\n",
       "                                        aligned_edit  \n",
       "1  REF:  i  soldati della pace dell'onu, che     ...  \n",
       "2  REF:  le forze di pace delle nazioni unite,   ...  \n",
       "4  REF:  secondo la causa,    i rifiuti del campo...  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08941afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### One-hot encoder for target labels for LinearRegression and RandomForest (used later in K-fold CV)\n",
    "\n",
    "y = np.array(df_train.subject_id)\n",
    "label_encoder = LabelBinarizer().fit(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5242a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.transform(y[[0,1,2,3,4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c85394a",
   "metadata": {},
   "source": [
    "## Selecting features to train the model on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084e0d92",
   "metadata": {},
   "source": [
    "### 1) Selecting only numerical features and scaling them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f018eaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns(dataframe: pd.DataFrame, dtype_include: list, name_exclude: list) -> pd.DataFrame:\n",
    "    \"\"\"Return a dataframe with only those columns that have a certain datatype and are not in a \"\"\"\n",
    "    df_selected = dataframe[[col for col in dataframe.columns if dataframe[col].dtype in dtype_include and col not in name_exclude]]\n",
    "    return df_selected\n",
    " \n",
    "X_train_numeric = select_columns(df_train, dtype_include = ['float32', 'int32'], name_exclude = ['bleu', 'chrf', 'ter', 'item_id'])\n",
    "X_test_numeric = select_columns(df_test, dtype_include = ['float32', 'int32'], name_exclude = ['bleu', 'chrf', 'ter', 'item_id'])\n",
    "# scaler = StandardScaler().fit(X_train_numeric)\n",
    "# X_test_numeric = scaler.transform(X_test_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e05cf67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edit_time</th>\n",
       "      <th>k_total</th>\n",
       "      <th>k_letter</th>\n",
       "      <th>k_digit</th>\n",
       "      <th>k_white</th>\n",
       "      <th>k_symbol</th>\n",
       "      <th>k_nav</th>\n",
       "      <th>k_erase</th>\n",
       "      <th>k_copy</th>\n",
       "      <th>k_cut</th>\n",
       "      <th>k_paste</th>\n",
       "      <th>n_pause_geq_300</th>\n",
       "      <th>len_pause_geq_300</th>\n",
       "      <th>n_pause_geq_1000</th>\n",
       "      <th>len_pause_geq_1000</th>\n",
       "      <th>num_annotations</th>\n",
       "      <th>n_insert</th>\n",
       "      <th>n_delete</th>\n",
       "      <th>n_substitute</th>\n",
       "      <th>n_shift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128.078995</td>\n",
       "      <td>179</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>97577</td>\n",
       "      <td>13</td>\n",
       "      <td>87014</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>141.500000</td>\n",
       "      <td>57</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>102782</td>\n",
       "      <td>2</td>\n",
       "      <td>98938</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.817001</td>\n",
       "      <td>67</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>52384</td>\n",
       "      <td>7</td>\n",
       "      <td>45450</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>190.141006</td>\n",
       "      <td>235</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>161226</td>\n",
       "      <td>16</td>\n",
       "      <td>146571</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>97.675003</td>\n",
       "      <td>61</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>69669</td>\n",
       "      <td>12</td>\n",
       "      <td>62854</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>45.687000</td>\n",
       "      <td>51</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>40032</td>\n",
       "      <td>5</td>\n",
       "      <td>38392</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>376.105988</td>\n",
       "      <td>63</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>350997</td>\n",
       "      <td>8</td>\n",
       "      <td>346590</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>143.360001</td>\n",
       "      <td>69</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>134002</td>\n",
       "      <td>7</td>\n",
       "      <td>129330</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>154.690002</td>\n",
       "      <td>36</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>103191</td>\n",
       "      <td>7</td>\n",
       "      <td>99549</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>286.171997</td>\n",
       "      <td>338</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>250327</td>\n",
       "      <td>37</td>\n",
       "      <td>234728</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>780 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       edit_time  k_total  k_letter  k_digit  k_white  k_symbol  k_nav  \\\n",
       "1     128.078995      179       102        0       14         2      0   \n",
       "2     141.500000       57        27        0        1         1     19   \n",
       "4      66.817001       67        52        0        4         3      0   \n",
       "5     190.141006      235       102        0       12         4     50   \n",
       "7      97.675003       61        41        0        8         0      0   \n",
       "...          ...      ...       ...      ...      ...       ...    ...   \n",
       "1163   45.687000       51        36        0        2         3      7   \n",
       "1164  376.105988       63        51        0        7         1      0   \n",
       "1166  143.360001       69        37        0        5         0     22   \n",
       "1167  154.690002       36        22        0        4         2      1   \n",
       "1169  286.171997      338       202        0       28         8     44   \n",
       "\n",
       "      k_erase  k_copy  k_cut  k_paste  n_pause_geq_300  len_pause_geq_300  \\\n",
       "1          60       0      0        0               36              97577   \n",
       "2           9       0      0        0                9             102782   \n",
       "4           8       0      0        0               19              52384   \n",
       "5          53       0      0        0               45             161226   \n",
       "7          11       0      0        1               26              69669   \n",
       "...       ...     ...    ...      ...              ...                ...   \n",
       "1163        3       0      0        0                9              40032   \n",
       "1164        4       0      0        0               17             350997   \n",
       "1166        5       0      0        0               14             134002   \n",
       "1167        7       0      0        0               14             103191   \n",
       "1169       56       0      0        0               68             250327   \n",
       "\n",
       "      n_pause_geq_1000  len_pause_geq_1000  num_annotations  n_insert  \\\n",
       "1                   13               87014                2       0.0   \n",
       "2                    2               98938                1       1.0   \n",
       "4                    7               45450                2       2.0   \n",
       "5                   16              146571                1       4.0   \n",
       "7                   12               62854                4       1.0   \n",
       "...                ...                 ...              ...       ...   \n",
       "1163                 5               38392                1       0.0   \n",
       "1164                 8              346590                1       4.0   \n",
       "1166                 7              129330                1       1.0   \n",
       "1167                 7               99549                1       2.0   \n",
       "1169                37              234728                1       2.0   \n",
       "\n",
       "      n_delete  n_substitute  n_shift  \n",
       "1          2.0          15.0      1.0  \n",
       "2          2.0           2.0      0.0  \n",
       "4          1.0           4.0      0.0  \n",
       "5          3.0           7.0      1.0  \n",
       "7          0.0           5.0      2.0  \n",
       "...        ...           ...      ...  \n",
       "1163       1.0           3.0      0.0  \n",
       "1164       1.0           5.0      0.0  \n",
       "1166       0.0           8.0      0.0  \n",
       "1167       0.0           3.0      0.0  \n",
       "1169       1.0          14.0      0.0  \n",
       "\n",
       "[780 rows x 20 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e5bfbd",
   "metadata": {},
   "source": [
    "### 1/A) Train and validate [LinearRegression, RandomForestClassifier] on [[TOP100%, TOP75%, TOP50%, TOP25%], [only_keystroke], [only_postedit]] numeric _training_ data using 10-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2139b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_regression_prediction(predictions):\n",
    "    \"\"\"Converts softmax regression values within a vector to one-hot encoding, based on argmax.\"\"\"\n",
    "    preds_one_hot = []\n",
    "    for vector in predictions:\n",
    "        argmax = np.argmax(vector)\n",
    "        tmp = []\n",
    "        for idx, pred in enumerate(vector):\n",
    "            if idx == argmax:\n",
    "                tmp.append(1)\n",
    "            else:\n",
    "                tmp.append(0)\n",
    "        preds_one_hot.append(tmp)\n",
    "    preds_one_hot = np.array(preds_one_hot)\n",
    "    return preds_one_hot\n",
    "\n",
    "\n",
    "def do_kfold_scoring(model, X, y, selector=None, scaling=True):\n",
    "    \"\"\"Performs a k-fold CV with given model on the supplied dataset\"\"\"\n",
    "    if selector:\n",
    "        X = selector.transform(X)\n",
    "    else:\n",
    "        X = X.to_numpy()\n",
    "    # Scaling has to be performed individually for each run, because the number of features may be different per\n",
    "    # each experiment, and the scaler requires same amount to transform once 'fitted'\n",
    "    if scaling:\n",
    "        X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    scores_train = []\n",
    "    scores_valid = []\n",
    "    skf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "    for train_index, valid_index in skf.split(X, y):\n",
    "        X_train, X_valid = X[train_index], X[valid_index]\n",
    "        y_train, y_valid = label_encoder.transform(y[train_index]), label_encoder.transform(y[valid_index])\n",
    "        model_fit = model.fit(X_train, y_train)\n",
    "        if model._estimator_type == 'regressor':\n",
    "            scores_train.append(accuracy_score(threshold_regression_prediction(model_fit.predict(X_train)), y_train))\n",
    "            scores_valid.append(accuracy_score(threshold_regression_prediction(model_fit.predict(X_valid)), y_valid))\n",
    "        else:\n",
    "            scores_train.append(model_fit.score(X_train, y_train))\n",
    "            scores_valid.append(model_fit.score(X_valid, y_valid))\n",
    "    print(\"Average train score:\", round(np.mean(scores_train), 3))\n",
    "    print(\"Average validation score:\", round(np.mean(scores_valid), 3))\n",
    "    \n",
    "def get_features_sorted(selector):\n",
    "    \"\"\"Returns a list of tuples, containing the name of the features and their relevance according to a KBest selector\"\"\"\n",
    "    features_sorted = sorted(zip(list(selector.get_feature_names_out()), list(selector.scores_)),\n",
    "                             key=lambda x: x[1], reverse=True)\n",
    "    return features_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6b69ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select all numeric features with SelectKBest and retrieve estimated importances\n",
    "kbest = SelectKBest(chi2, k=len(X_train_numeric.columns)).fit(X_train_numeric, y)\n",
    "kbest_sorted = get_features_sorted(kbest)\n",
    "kbest_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf657f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LinearRegression\n",
    "lr_model = LinearRegression(n_jobs=-1)\n",
    "# RandomForest\n",
    "rf_model = RandomForestClassifier(n_jobs=-1)\n",
    "# Ridge Regression - perform a GridSearchCV on all training data to estimate optimal 'alpha' before applying K-fold CV\n",
    "parameters = {'alpha':[0.1, 0.25, 0.5, 1, 2, 5, 10]}\n",
    "ridge_model = Ridge()\n",
    "Ridge_reg= GridSearchCV(ridge_model, parameters, scoring='neg_mean_squared_error',cv=5)\n",
    "Ridge_reg.fit(X_train_numeric.to_numpy(),label_encoder.fit_transform(y))\n",
    "ridge_model = Ridge_reg.best_estimator_\n",
    "\n",
    "models = [lr_model, rf_model, ridge_model]\n",
    "\n",
    "def run_numeric_data_experiments(model): \n",
    "    # try it on all numeric data, as well as only keystroke data, only postedits data, etc\n",
    "    top_columns =[[pair[0] for pair in kbest_sorted[0:int(x*len(X_train_numeric.columns))]] for x in [1, 0.75, 0.5, 0.25]]\n",
    "\n",
    "    print(f\"{'-'*50}\\n\\n\\nPERFORMING EXPERIMENTS WITH [{model}]...\\n{'-'*50}\")\n",
    "    # Train and validate on TOP 100%, 75%, 50% and 25% features of the data\n",
    "    for top, ratio in zip(top_columns, [1, 0.75, 0.5, 0.25]):\n",
    "        kbest_ = SelectKBest(chi2, k=int(len(X_train_numeric.columns)*ratio)).fit(X_train_numeric, y)\n",
    "        print(f\"Performing 10-Fold CV on top {int(ratio*100)}% features of the data...\")\n",
    "        do_kfold_scoring(model, X_train_numeric, y, selector=kbest_, scaling=True)\n",
    "        print(\"*\"*40, \"\\n\")\n",
    "\n",
    "    # Train and validate on keystroke features data\n",
    "    print(f\"\\n{'*'*40}\\n[KEYSTROKE FEATURES]\")\n",
    "    keystroke_columns = [col for col in X_train_numeric.columns if col.startswith('k_')]\n",
    "    do_kfold_scoring(model, X_train_numeric[keystroke_columns], y, scaling=True)\n",
    "\n",
    "    # Train and validate on postedit features data\n",
    "    print(f\"\\n{'*'*40}\\n[POSTEDIT FEATURES]\")\n",
    "    postedit_columns = [col for col in X_train_numeric.columns if col.startswith('n_')]\n",
    "    do_kfold_scoring(model, X_train_numeric[postedit_columns], y, scaling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2763eb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    run_numeric_data_experiments(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765c0988",
   "metadata": {},
   "source": [
    "### 2) Experimenting with linguistic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d11b601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features of Machine translated sentences\n",
    "lingfeat_train_mt = pd.read_csv('Linguistic_features/train_mt.csv', sep=\"\\t\").drop(columns=['Filename'])\n",
    "lingfeat_test_mt = pd.read_csv('Linguistic_features/test_mt.csv', sep='\\t').drop(columns=['Filename'])\n",
    "\n",
    "lingfeat_train_tgt = pd.read_csv('Linguistic_features/train_tgt.csv', sep=\"\\t\").drop(columns=['Filename'])\n",
    "lingfeat_test_tgt = pd.read_csv('Linguistic_features/test_tgt.csv', sep=\"\\t\").drop(columns=['Filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a99be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lingfeat_train_mt.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba64f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "lingfeat_train_tgt.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5f6cc1",
   "metadata": {},
   "source": [
    "### Remove linguistic features that are not present in all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400c3000",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## First remove features that are not present in all dataframes\n",
    "def intersection(lst1, lst2):\n",
    "    return list(set(lst1) & set(lst2))\n",
    "\n",
    "all_columns = [list(lingfeat_train_mt.columns), list(lingfeat_train_tgt.columns), list(lingfeat_test_mt.columns), list(lingfeat_test_tgt.columns)]\n",
    "merged_columns = list(lingfeat_train_mt.columns)\n",
    "for cols in all_columns:\n",
    "    merged_columns = intersection(merged_columns, cols)\n",
    "\n",
    "lingfeat_train_mt = lingfeat_train_mt[[col for col in lingfeat_train_mt.columns if col in merged_columns]]\n",
    "lingfeat_train_tgt = lingfeat_train_tgt[[col for col in lingfeat_train_tgt.columns if col in merged_columns]]\n",
    "lingfeat_test_mt = lingfeat_test_mt[[col for col in lingfeat_test_mt.columns if col in merged_columns]]\n",
    "lingfeat_test_tgt = lingfeat_test_tgt[[col for col in lingfeat_test_tgt.columns if col in merged_columns]]\n",
    "\n",
    "assert len(lingfeat_train_mt.columns) == len(lingfeat_train_tgt.columns) == len(lingfeat_test_mt.columns) == len(lingfeat_test_tgt.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d70fde",
   "metadata": {},
   "source": [
    "### Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb8a4c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_ling = lingfeat_train_tgt.subtract(lingfeat_train_mt).abs()\n",
    "\n",
    "def run_linguistic_data_experiments(model, features): \n",
    "    print(f\"{'-'*50}\\n\\n\\nPERFORMING EXPERIMENTS WITH [{model}]...\\n{'-'*50}\")\n",
    "    do_kfold_scoring(model, features, y, selector=None, scaling=True)\n",
    "    print(\"*\"*40, \"\\n\")\n",
    "        \n",
    "for model in models:\n",
    "    run_linguistic_data_experiments(model, X_train_ling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b052fab",
   "metadata": {},
   "source": [
    "### 3) Experimenting with combination of behavioral numeric and linguistic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4b5b08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_combined = pd.concat([X_train_numeric.reset_index(drop=True), X_train_ling.reset_index(drop=True)], axis=1)\n",
    "X_train_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0426f95c",
   "metadata": {},
   "source": [
    "### Run experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb6a836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_combined_data_experiments(model, features): \n",
    "    print(f\"{'-'*50}\\n\\n\\nPERFORMING EXPERIMENTS WITH [{model}]...\\n{'-'*50}\")\n",
    "    do_kfold_scoring(model, features, y, selector=None, scaling=False)\n",
    "    print(\"*\"*40, \"\\n\")\n",
    "        \n",
    "for model in models:\n",
    "    run_combined_data_experiments(model, X_train_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22153945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_python3",
   "language": "python",
   "name": ".venv_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
